{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T08:54:35.156479Z",
     "start_time": "2020-12-09T08:53:27.273205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name 'bert-base-uncased' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt' was a path or url but couldn't find any file associated to this path or url.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T08:56:36.909248Z",
     "start_time": "2020-12-09T08:56:31.370711Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 231508/231508 [00:03<00:00, 70048.73B/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输入格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为BERT是一个预训练的模型，它期望以特定的格式输入数据，所以我们需要：\n",
    "\n",
    "- 句子的开始([CLS])和分隔/结尾([SEP])的特别标记\n",
    "\n",
    "- 符合BERT中使用的固定词汇表的标记\n",
    "\n",
    "- BERT‘s tokenizer中的token id\n",
    "\n",
    "- 掩码id，以指示序列中的哪些元素是令牌，哪些是填充元素\n",
    "\n",
    "- 段id用于区分不同的句子\n",
    "\n",
    "- 用于显示令牌在序列中的位置嵌入\n",
    "\n",
    "幸运的是，这个接口为我们处理了这些输入规范中的一些，因此我们只需要手动创建其中的一些(我们将在另一个教程中重新讨论其他输入)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特殊的标记\n",
    "BERT可以接受一到两句话作为输入，并希望每句话的开头和结尾都有特殊的标记：\n",
    "\n",
    "2个句子的输入:\n",
    "\n",
    "[CLS] the man went to the store [SEP] he bought a gallon of milk [SEP]\n",
    "\n",
    "1个句子的输入:\n",
    "\n",
    "[CLS] the man went to the store [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T08:58:38.604616Z",
     "start_time": "2020-12-09T08:58:38.601618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank. [SEP]\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Here is the sentence I want embeddings for.\"\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\t\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "marked_text1 = \"[CLS] \" + text1 + \" [SEP]\"\n",
    "print (marked_text)\n",
    "#[CLS] After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank. [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们导入了一个BERT-specific tokenizer，让我们看看输出："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:20:18.797839Z",
     "start_time": "2020-12-09T09:20:18.793858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "print (tokenized_text)\n",
    "#['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T08:58:54.912947Z",
     "start_time": "2020-12-09T08:58:54.908958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = tokenizer.tokenize(marked_text1)\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意“embeddings”一词是如何表示的:\n",
    "\n",
    "[‘em’, ‘##bed’, ‘##ding’, ‘##s’]\n",
    "\n",
    "原来的单词被分成更小的子单词和字符。这些子单词前面的两个#号只是我们的tokenizer用来表示这个子单词或字符是一个更大单词的一部分，并在其前面加上另一个子单词的方法。因此，例如，' ##bed ' token与' bed 'token是分开的，当一个较大的单词中出现子单词bed时，使用第一种方法，当一个独立的token “thing you sleep on”出现时，使用第二种方法。\n",
    "\n",
    "为什么会这样？这是因为BERT tokenizer 是用WordPiece模型创建的。这个模型使用贪心法创建了一个固定大小的词汇表，其中包含单个字符、子单词和最适合我们的语言数据的单词。由于我们的BERT tokenizer模型的词汇量限制大小为30,000，因此，用WordPiece模型生成一个包含所有英语字符的词汇表，再加上该模型所训练的英语语料库中发现的~30,000个最常见的单词和子单词。这个词汇表包含个东西：\n",
    "\n",
    "- 整个单词\n",
    "\n",
    "- 出现在单词前面或单独出现的子单词(“em”(如embeddings中的“em”)与“go get em”中的独立字符序列“em”分配相同的向量)\n",
    "\n",
    "- 不在单词前面的子单词，在前面加上“##”来表示这种情况\n",
    "\n",
    "- 单个字符\n",
    "\n",
    "要在此模型下对单词进行记号化，tokenizer首先检查整个单词是否在词汇表中。如果没有，则尝试将单词分解为词汇表中包含的尽可能大的子单词，最后将单词分解为单个字符。注意，由于这个原因，我们总是可以将一个单词表示为至少是它的单个字符的集合。\n",
    "\n",
    "因此，不是将词汇表中的单词分配给诸如“OOV”或“UNK”之类的全集令牌，而是将词汇表中没有的单词分解为子单词和字符令牌，然后我们可以为它们生成嵌入。\n",
    "\n",
    "因此，我们没有将“embeddings”和词汇表之外的每个单词分配给一个重载的未知词汇表标记，而是将其拆分为子单词标记[' em '、' ##bed '、' ##ding '、' ##s ']，这些标记将保留原单词的一些上下文含义。我们甚至可以平均这些子单词的嵌入向量来为原始单词生成一个近似的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是词汇表中包含的一些令牌示例。以两个#号开头的标记是子单词或单个字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T08:59:57.621278Z",
     "start_time": "2020-12-09T08:59:57.613271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knight',\n",
       " 'lap',\n",
       " 'survey',\n",
       " 'ma',\n",
       " '##ow',\n",
       " 'noise',\n",
       " 'billy',\n",
       " '##ium',\n",
       " 'shooting',\n",
       " 'guide',\n",
       " 'bedroom',\n",
       " 'priest',\n",
       " 'resistance',\n",
       " 'motor',\n",
       " 'homes',\n",
       " 'sounded',\n",
       " 'giant',\n",
       " '##mer',\n",
       " '150',\n",
       " 'scenes']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要调用tokenizer来匹配tokens在tokenizer词汇表中的索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:20:25.550675Z",
     "start_time": "2020-12-09T09:20:25.545690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[CLS]', 101)\n",
      "('after', 2044)\n",
      "('stealing', 11065)\n",
      "('money', 2769)\n",
      "('from', 2013)\n",
      "('the', 1996)\n",
      "('bank', 2924)\n",
      "('vault', 11632)\n",
      "(',', 1010)\n",
      "('the', 1996)\n",
      "('bank', 2924)\n",
      "('robber', 27307)\n",
      "('was', 2001)\n",
      "('seen', 2464)\n",
      "('fishing', 5645)\n",
      "('on', 2006)\n",
      "('the', 1996)\n",
      "('mississippi', 5900)\n",
      "('river', 2314)\n",
      "('bank', 2924)\n",
      "('.', 1012)\n",
      "('[SEP]', 102)\n"
     ]
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print (tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT接受了句子对的训练，并期望使用1和0来区分这两个句子。也就是说，对于“tokenized_text”中的每个标记，我们必须指定它属于哪个句子：句子0(一系列0)或句子1(一系列1)。对于我们的目的，单句输入只需要一系列的1，所以我们将为输入语句中的每个标记创建一个1向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想处理两个句子，请将第一个句子中的每个单词加上“[SEP]”token赋值为0，第二个句子中的所有token赋值为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:20:28.812973Z",
     "start_time": "2020-12-09T09:20:28.808984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 运行一下我们的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们需要将数据转换为torch张量并调用BERT模型。BERT PyTorch接口要求数据使用torch张量而不是Python列表，所以我们在这里转换列表——这不会改变形状或数据。\n",
    "\n",
    "eval()将我们的模型置于评估模式，而不是训练模式。在这种情况下，评估模式关闭了训练中使用的dropout正则化。\n",
    "\n",
    "调用 from_pretrained 将从网上获取模型。当我们加载 bert-base-uncased时，我们会在日志中看到打印的模型定义。该模型是一个12层的深度神经网络！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:20:37.264356Z",
     "start_time": "2020-12-09T09:20:31.613791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\t\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，让我们获取网络的隐藏状态。\n",
    "\n",
    "torch.no_grad禁用梯度计算，节省内存，并加快计算速度(我们不需要梯度或反向传播，因为我们只是运行向前传播)。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:20:40.678871Z",
     "start_time": "2020-12-09T09:20:40.618035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict hidden states features for each layer\t\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个模型的全部隐藏状态存储在对象“encoded_layers”中，有点令人眼花缭乱。这个对象有四个维度，顺序如下：\n",
    "\n",
    "- 层数(12层)\n",
    "\n",
    "- batch号(1句)\n",
    "\n",
    "- 单词/令牌号(在我们的句子中有22个令牌)\n",
    "\n",
    "- 隐藏单元/特征号(768个特征)\n",
    "\n",
    "这是202,752个值来唯一表示我们的一句话！\n",
    "\n",
    "第二维度，是批处理大小，用于同时向模型提交多个句子，这里，我们只有一个句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:20:43.070666Z",
     "start_time": "2020-12-09T09:20:43.065649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:20:44.846358Z",
     "start_time": "2020-12-09T09:20:44.841372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:20:47.343073Z",
     "start_time": "2020-12-09T09:20:47.338087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 22\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\t\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\t\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 0\t\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们快速查看一下给定层和token的值范围。\n",
    "\n",
    "你将发现，所有层和token的范围都非常相似，大多数值位于[- 2,2]之间，少量值位于-10左右。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:24:32.745568Z",
     "start_time": "2020-12-09T09:20:56.544361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按层对值进行分组对于模型是有意义的，但是出于我们的目的，我们希望按token对值进行分组。\n",
    "\n",
    "下面的代码只是重新构造这些值，这样我们就有了它们的形式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:24:39.714498Z",
     "start_time": "2020-12-09T09:24:39.708514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 22\n",
      "Number of layers per token: 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the hidden state embeddings into single token vectors\n",
    "# Holds the list of 12 layer embeddings for each token\n",
    "# Will have the shape: [# tokens, # layers, # features]\n",
    "token_embeddings = [] \n",
    "# For each token in the sentence...\n",
    "for token_i in range(len(tokenized_text)):\n",
    "    \n",
    "    # Holds 12 layers of hidden states for each token\n",
    "    hidden_layers = [] \n",
    "    # For each of the 12 layers...\n",
    "    for layer_i in range(len(encoded_layers)):\n",
    "    # Lookup the vector for `token_i` in `layer_i`\n",
    "        vec = encoded_layers[layer_i][batch_i][token_i]\n",
    "        hidden_layers.append(vec)\n",
    "    token_embeddings.append(hidden_layers)\n",
    "# Sanity check the dimensions:\n",
    "print (\"Number of tokens in sequence:\", len(token_embeddings))\n",
    "print (\"Number of layers per token:\", len(token_embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从隐藏状态中构建词向量和句向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们怎么处理这些隐藏状态？我们想要得到每个token的单独向量，或者可能是整个句子的单个向量表示，但是对于输入的每个token，我们有12个长度为768的单独向量。\n",
    "\n",
    "为了得到单独的向量，我们需要组合一些层向量……但是哪个层或层的组合提供了最好的表示？BERT的作者通过将不同的向量组合作为输入特征输入到一个用于命名实体识别任务的BiLSTM中，并观察得到的F1分数来测试这一点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然最后四层的连接在这个特定的任务上产生了最好的结果，但是许多其他方法紧随其后，并且通常建议为你的特定应用程序测试不同的版本：结果可能会有所不同。\n",
    "\n",
    "注意到BERT的不同层编码非常不同的信息，可以部分地证明这一点，因此适当的池化策略将根据应用的不同而改变，因为不同的层化编码不同的信息。Hanxiao对这个话题的讨论是相关的，他们的实验是在新闻数据集上训练不同层次的PCA可视化，并观察不同池策略下四类分离的差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果是，正确的池化策略(平均值、最大值、连接等等)和使用的层(最后四层、全部、最后一层等等)依赖于应用。对池化策略的讨论既适用于整个语句嵌入，也适用于类似于elmo的单个token嵌入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了给你一些例子，让我们用最后四层的连接和求和来创建单词向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:24:43.262071Z",
     "start_time": "2020-12-09T09:24:43.256087Z"
    }
   },
   "outputs": [],
   "source": [
    "concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\t\n",
    "summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 句向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要为整个句子获得一个向量，我们有多个依赖于应用的策略，但是一个简单的方法是对每个token的倒数第二个隐藏层求平均，生成一个768长度的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:24:46.045568Z",
     "start_time": "2020-12-09T09:24:46.040580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: 768\n"
     ]
    }
   ],
   "source": [
    "sentence_embedding = torch.mean(encoded_layers[11], 1)\t\n",
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 确定上下文相关的向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了确认这些向量的值实际上是上下文相关的，让我们看一下下面这句话的输出(如果你想试试这个，你必须从顶部运行这个例子，用下面的句子替换我们原来的句子)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:24:49.229921Z",
     "start_time": "2020-12-09T09:24:49.224935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\n",
      "0 [CLS]\n",
      "1 after\n",
      "2 stealing\n",
      "3 money\n",
      "4 from\n",
      "5 the\n",
      "6 bank\n",
      "7 vault\n",
      "8 ,\n",
      "9 the\n",
      "10 bank\n",
      "11 robber\n",
      "12 was\n",
      "13 seen\n",
      "14 fishing\n",
      "15 on\n",
      "16 the\n",
      "17 mississippi\n",
      "18 river\n",
      "19 bank\n",
      "20 .\n",
      "21 [SEP]\n"
     ]
    }
   ],
   "source": [
    "print (text)\n",
    "for i,x in enumerate(tokenized_text):\n",
    "    print (i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:24:53.534706Z",
     "start_time": "2020-12-09T09:24:53.528694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'bank' as in 'bank robber':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1868, -1.5298, -1.3770,  1.0648,  3.1446,  1.4003, -4.2407,  1.3946,\n",
       "        -0.1170, -1.8777,  0.1091, -0.3862,  0.6744,  2.1924, -4.5306])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'bank' as in 'bank robber':\")\n",
    "\n",
    "summed_last_4_layers[10][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:25:16.653877Z",
     "start_time": "2020-12-09T09:25:16.648891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'bank' as in 'bank vault':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1319, -2.1413, -1.6260,  0.8638,  3.3173,  0.1797, -4.4853,  3.1215,\n",
       "        -0.9740, -3.1780,  0.1045, -1.5481,  0.4758,  1.1703, -4.4859])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'bank' as in 'bank vault':\")\n",
    "summed_last_4_layers[6][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:25:27.718484Z",
     "start_time": "2020-12-09T09:25:27.712501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First fifteen values of 'bank' as in 'river bank':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1295, -1.4724, -0.7296, -0.0901,  2.4970,  0.5330,  0.9742,  5.1834,\n",
       "        -1.0692, -1.5941,  1.9261,  0.7119, -0.9809,  1.2127, -2.9812])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"First fifteen values of 'bank' as in 'river bank':\")\n",
    "summed_last_4_layers[19][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，这些都是不同的向量，它们应该是不同的，虽然单词“bank”是相同的，但在我们的每个句子中，它都有不同的含义，有时意义非常不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个句子中，我们有三种不同的“bank”用法，其中两种几乎是相同的。让我们检查余弦相似度，看看是不是这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:28:58.846253Z",
     "start_time": "2020-12-09T09:28:58.266382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of 'bank' as in 'bank robber' to 'bank' as in 'bank vault': 0.9456754\n",
      "Similarity of 'bank' as in 'bank robber' to 'bank' as in 'river bank': 0.6797334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"river bank\"\n",
    "different_bank = cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[19].reshape(1,-1))[0][0]\n",
    "# Compare \"bank\" as in \"bank robber\" to \"bank\" as in \"bank vault\"\n",
    "same_bank = cosine_similarity(summed_last_4_layers[10].reshape(1,-1), summed_last_4_layers[6].reshape(1,-1))[0][0]\n",
    "print (\"Similarity of 'bank' as in 'bank robber' to 'bank' as in 'bank vault':\",  same_bank)\n",
    "print (\"Similarity of 'bank' as in 'bank robber' to 'bank' as in 'river bank':\",  different_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他：特殊的tokens，OOV单词，相似度度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特殊tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，虽然“[CLS]”用作分类任务的“聚合表示”，但对于高质量的句子嵌入向量来说，这不是最佳选择。根据BERT作者Jacob Devlin:\n",
    "\n",
    "我不确定这些向量是什么，因为BERT不能生成有意义的句子向量。这似乎是在对单词tokens进行平均池化，以获得一个句子向量，但我们从未建议这将生成有意义的句子表示。”\n",
    "\n",
    "(但是，如果对模型进行微调，[CLS] token确实变得有意义，其中该token的最后一个隐藏层用作序列分类的“句子向量”。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词汇表之外的单词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于由多个句子和字符级嵌入组成的词汇表之外的单词，还有一个进一步的问题，即如何最好地恢复这种嵌入。平均嵌入是最直接的解决方案(在类似的嵌入模型中依赖于子单词词汇表(如fasttext))，但是子单词嵌入的总和和简单地使用最后一个token嵌入(记住向量是上下文敏感的)是可接受的替代策略。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相似度度量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "值得注意的是，单词级相似度比较不适用于BERT embeddings，因为这些嵌入是上下文相关的，这意味着单词vector会根据它出现在的句子而变化。这就允许了像一词多义这样的奇妙的东西，例如，你的表示编码了river “bank”，而不是金融机构“bank”，但却使得直接的词与词之间的相似性比较变得不那么有价值。但是，对于句子嵌入相似性比较仍然是有效的，这样就可以对一个句子查询其他句子的数据集，从而找到最相似的句子。根据使用的相似度度量，得到的相似度值将比相似度输出的相对排序提供的信息更少，因为许多相似度度量对向量空间(例如，等权重维度)做了假设，而这些假设不适用于768维向量空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
