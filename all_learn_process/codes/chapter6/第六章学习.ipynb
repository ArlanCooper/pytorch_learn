{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 猫狗分类实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:48:45.305537Z",
     "start_time": "2020-12-14T08:48:45.214780Z"
    }
   },
   "outputs": [],
   "source": [
    "from config import opt\n",
    "import os\n",
    "import torch as t\n",
    "import models\n",
    "from data.dataset import DogCat\n",
    "from torch.utils.data import DataLoader\n",
    "from torchnet import meter\n",
    "from utils.visualize import Visualizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:29:03.293548Z",
     "start_time": "2020-12-14T08:29:02.928529Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "\n",
    "class DogCat(data.Dataset):\n",
    "    \n",
    "    def __init__(self, root, transforms=None, train=True, test=False):\n",
    "        \"\"\"\n",
    "        目标：获取所有图片地址，并根据训练、验证、测试划分数据\n",
    "        \"\"\"\n",
    "        self.test = test\n",
    "        imgs = [os.path.join(root, img) for img in os.listdir(root)] \n",
    "\n",
    "        # test1: data/test1/8973.jpg\n",
    "        # train: data/train/cat.10004.jpg \n",
    "        if self.test:\n",
    "            imgs = sorted(imgs, key=lambda x: int(x.split('.')[-2].split('/')[-1]))\n",
    "        else:\n",
    "            imgs = sorted(imgs, key=lambda x: int(x.split('.')[-2]))\n",
    "            \n",
    "        imgs_num = len(imgs)\n",
    "        \n",
    "        # 划分训练、验证集，验证:训练 = 3:7\n",
    "        if self.test:\n",
    "            self.imgs = imgs\n",
    "        elif train:\n",
    "            self.imgs = imgs[:int(0.7*imgs_num)]\n",
    "        else :\n",
    "            self.imgs = imgs[int(0.7*imgs_num):]            \n",
    "    \n",
    "        if transforms is None:\n",
    "        \n",
    "            # 数据转换操作，测试验证和训练的数据转换有所区别\n",
    "\t        \n",
    "            normalize = T.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                                     std = [0.229, 0.224, 0.225])\n",
    "\n",
    "            # 测试集和验证集\n",
    "            if self.test or not train: \n",
    "                self.transforms = T.Compose([\n",
    "                    T.Resize(224),\n",
    "                    T.CenterCrop(224),\n",
    "                    T.ToTensor(),\n",
    "                    normalize\n",
    "                ]) \n",
    "            # 训练集\n",
    "            else :\n",
    "                self.transforms = T.Compose([\n",
    "                    T.Resize(256),\n",
    "                    T.RandomReSizedCrop(224),\n",
    "                    T.RandomHorizontalFlip(),\n",
    "                    T.ToTensor(),\n",
    "                    normalize\n",
    "                ]) \n",
    "                \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        返回一张图片的数据\n",
    "        对于测试集，没有label，返回图片id，如1000.jpg返回1000\n",
    "        \"\"\"\n",
    "        img_path = self.imgs[index]\n",
    "        if self.test: \n",
    "             label = int(self.imgs[index].split('.')[-2].split('/')[-1])\n",
    "        else: \n",
    "             label = 1 if 'dog' in img_path.split('/')[-1] else 0\n",
    "        data = Image.open(img_path)\n",
    "        data = self.transforms(data)\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集中所有图片的个数\n",
    "        \"\"\"\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于数据集使用的注意事项，在上一章中已经提到，将文件读取等费时操作放在`__getitem__`函数中，利用多进程加速。避免一次性将所有图片都读进内存，不仅费时也会占用较大内存，而且不易进行数据增强等操作。另外在这里，我们将训练集中的30%作为验证集，可用来检查模型的训练效果，避免过拟合。在使用时，我们可通过dataloader加载数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DogCat(opt.train_data_root, train=True)\n",
    "trainloader = DataLoader(train_dataset,\n",
    "                        batch_size = opt.batch_size,\n",
    "                        shuffle = True,\n",
    "                        num_workers = opt.num_workers)\n",
    "                  \n",
    "for ii, (data, label) in enumerate(trainloader):\n",
    "\ttrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的定义主要保存在`models/`目录下，其中`BasicModule`是对`nn.Module`的简易封装，提供快速加载和保存模型的接口。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T08:57:21.039856Z",
     "start_time": "2020-12-14T08:57:21.034870Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasicModule(t.nn.Module):\n",
    "    \"\"\"\n",
    "    封装了nn.Module，主要提供save和load两个方法\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BasicModule,self).__init__()\n",
    "        self.model_name = str(type(self)) # 模型的默认名字\n",
    "\n",
    "    def load(self, path):\n",
    "        \"\"\"\n",
    "        可加载指定路径的模型\n",
    "        \"\"\"\n",
    "        self.load_state_dict(t.load(path))\n",
    "\n",
    "    def save(self, name=None):\n",
    "        \"\"\"\n",
    "        保存模型，默认使用“模型名字+时间”作为文件名，\n",
    "        如AlexNet_0710_23:57:29.pth\n",
    "        \"\"\"\n",
    "        if name is None:\n",
    "            prefix = 'checkpoints/' + self.model_name + '_'\n",
    "            name = time.strftime(prefix + '%m%d_%H:%M:%S.pth')\n",
    "        t.save(self.state_dict(), name)\n",
    "        return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实际使用中，直接调用`model.save()`及`model.load(opt.load_path)`即可。\n",
    "\n",
    "其它自定义模型一般继承`BasicModule`，然后实现自己的模型。其中`AlexNet.py`实现了AlexNet，`ResNet34`实现了ResNet34。在`models/__init__py`中，代码如下：\n",
    "```python\n",
    "from .AlexNet import AlexNet\n",
    "from .ResNet34 import ResNet34\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样在主函数中就可以写成：\n",
    "\n",
    "```python\n",
    "from models import AlexNet\n",
    "或\n",
    "import models\n",
    "model = models.AlexNet()\n",
    "或\n",
    "import models\n",
    "model = getattr('models', 'AlexNet')()\n",
    "```\n",
    "\n",
    "其中最后一种写法最为关键，这意味着我们可以通过字符串直接指定使用的模型，而不必使用判断语句，也不必在每次新增加模型后都修改代码。新增模型后只需要在`models/__init__.py`中加上`from .new_module import new_module`即可。\n",
    "\n",
    "其它关于模型定义的注意事项，在上一章中已详细讲解，这里就不再赘述，总结起来就是：\n",
    "\n",
    "- 尽量使用`nn.Sequential`（比如AlexNet）\n",
    "- 将经常使用的结构封装成子Module（比如GoogLeNet的Inception结构，ResNet的Residual Block结构）\n",
    "- 将重复且有规律性的结构，用函数生成（比如VGG的多种变体，ResNet多种变体都是由多个重复卷积层组成）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 工具函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在项目中，我们可能会用到一些helper方法，这些方法可以统一放在`utils/`文件夹下，需要使用时再引入。在本例中主要是封装了可视化工具visdom的一些操作，其代码如下，在本次实验中只会用到`plot`方法，用来统计损失信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:01:24.856526Z",
     "start_time": "2020-12-14T09:01:24.846587Z"
    }
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class Visualizer(object):\n",
    "    \"\"\"\n",
    "    封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`\n",
    "    或者`self.function`调用原生的visdom接口\n",
    "    比如 \n",
    "    self.text('hello visdom')\n",
    "    self.histogram(t.randn(1000))\n",
    "    self.line(t.arange(0, 10),t.arange(1, 11))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env='default', **kwargs):\n",
    "        self.vis = visdom.Visdom(env=env, **kwargs)\n",
    "        \n",
    "        # 画的第几个数，相当于横坐标\n",
    "        # 保存（’loss',23） 即loss的第23个点\n",
    "        self.index = {} \n",
    "        self.log_text = ''\n",
    "    def reinit(self, env='default', **kwargs):\n",
    "        \"\"\"\n",
    "        修改visdom的配置\n",
    "        \"\"\"\n",
    "        self.vis = visdom.Visdom(env=env, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def plot_many(self, d):\n",
    "        \"\"\"\n",
    "        一次plot多个\n",
    "        @params d: dict (name, value) i.e. ('loss', 0.11)\n",
    "        \"\"\"\n",
    "        for k, v in d.items():\n",
    "            self.plot(k, v)\n",
    "\n",
    "    def img_many(self, d):\n",
    "        for k, v in d.items():\n",
    "            self.img(k, v)\n",
    "\n",
    "    def plot(self, name, y, **kwargs):\n",
    "        \"\"\"\n",
    "        self.plot('loss', 1.00)\n",
    "        \"\"\"\n",
    "        x = self.index.get(name, 0)\n",
    "        self.vis.line(Y=np.array([y]), X=np.array([x]),\n",
    "                      win=name,\n",
    "                      opts=dict(title=name),\n",
    "                      update=None if x == 0 else 'append',\n",
    "                      **kwargs\n",
    "                      )\n",
    "        self.index[name] = x + 1\n",
    "\n",
    "    def img(self, name, img_, **kwargs):\n",
    "        \"\"\"\n",
    "        self.img('input_img', t.Tensor(64, 64))\n",
    "        self.img('input_imgs', t.Tensor(3, 64, 64))\n",
    "        self.img('input_imgs', t.Tensor(100, 1, 64, 64))\n",
    "        self.img('input_imgs', t.Tensor(100, 3, 64, 64), nrows=10)\n",
    "\n",
    "        !!! don't ~~self.img('input_imgs', t.Tensor(100, 64, 64), nrows=10)~~ !!!\n",
    "        \"\"\"\n",
    "        self.vis.images(img_.cpu().numpy(),\n",
    "                       win=name,\n",
    "                       opts=dict(title=name),\n",
    "                       **kwargs\n",
    "                       )\n",
    "\n",
    "    def log(self, info, win='log_text'):\n",
    "        \"\"\"\n",
    "        self.log({'loss':1, 'lr':0.0001})\n",
    "        \"\"\"\n",
    "\n",
    "        self.log_text += ('[{time}] {info} <br>'.format(\n",
    "                            time=time.strftime('%m%d_%H%M%S'),\\\n",
    "                            info=info)) \n",
    "        self.vis.text(self.log_text, win)   \n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        \"\"\"\n",
    "        自定义的plot,image,log,plot_many等除外\n",
    "        self.function 等价于self.vis.function\n",
    "        \"\"\"\n",
    "        return getattr(self.vis, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配置文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在模型定义、数据处理和训练等过程都有很多变量，这些变量应提供默认值，并统一放置在配置文件中，这样在后期调试、修改代码或迁移程序时会比较方便，在这里我们将所有可配置项放在`config.py`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:02:35.138960Z",
     "start_time": "2020-12-14T09:02:35.134970Z"
    }
   },
   "outputs": [],
   "source": [
    "class DefaultConfig(object):\n",
    "    env = 'default' # visdom 环境\n",
    "    model = 'AlexNet' # 使用的模型，名字必须与models/__init__.py中的名字一致\n",
    "    \n",
    "    train_data_root = './data/train/' # 训练集存放路径\n",
    "    test_data_root = './data/test1' # 测试集存放路径\n",
    "    load_model_path = 'checkpoints/model.pth' # 加载预训练的模型的路径，为None代表不加载\n",
    "\n",
    "    batch_size = 128 # batch size\n",
    "    use_gpu = True # use GPU or not\n",
    "    num_workers = 4 # how many workers for loading data\n",
    "    print_freq = 20 # print info every N batch\n",
    "\n",
    "    debug_file = '/tmp/debug' # if os.path.exists(debug_file): enter ipdb\n",
    "    result_file = 'result.csv'\n",
    "      \n",
    "    max_epoch = 10\n",
    "    lr = 0.1 # initial learning rate\n",
    "    lr_decay = 0.95 # when val_loss increase, lr = lr*lr_decay\n",
    "    weight_decay = 1e-4 # 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可配置的参数主要包括：\n",
    "\n",
    "- 数据集参数（文件路径、batch_size等）\n",
    "- 训练参数（学习率、训练epoch等）\n",
    "- 模型参数\n",
    "\n",
    "这样我们在程序中就可以这样使用：\n",
    "\n",
    "```\n",
    "import models\n",
    "from config import DefaultConfig\n",
    "\n",
    "opt = DefaultConfig()\n",
    "lr = opt.lr\n",
    "model = getattr(models, opt.model)\n",
    "dataset = DogCat(opt.train_data_root)\n",
    "```\n",
    "\n",
    "这些都只是默认参数，在这里还提供了更新函数，根据字典更新配置参数。\n",
    "\n",
    "```\n",
    "def parse(self, kwargs):\n",
    "        \"\"\"\n",
    "        根据字典kwargs 更新 config参数\n",
    "        \"\"\"\n",
    "        # 更新配置参数\n",
    "        for k, v in kwargs.items():\n",
    "            if not hasattr(self, k):\n",
    "                # 警告还是报错，取决于你个人的喜好\n",
    "                warnings.warn(\"Warning: opt has not attribut %s\" %k)\n",
    "            setattr(self, k, v)\n",
    "            \n",
    "        # 打印配置信息\t\n",
    "        print('user config:')\n",
    "        for k, v in self.__class__.__dict__.items():\n",
    "            if not k.startswith('__'):\n",
    "                print(k, getattr(self, k))\n",
    "```\n",
    "\n",
    "这样我们在实际使用时，并不需要每次都修改`config.py`，只需要通过命令行传入所需参数，覆盖默认配置即可。\n",
    "\n",
    "例如：\n",
    "\n",
    "```\n",
    "opt = DefaultConfig()\n",
    "new_config = {'lr':0.1,'use_gpu':False}\n",
    "opt.parse(new_config)\n",
    "opt.lr == 0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在讲解主程序`main.py`之前，我们先来看看2017年3月谷歌开源的一个命令行工具`fire`[^3] ，通过`pip install fire`即可安装。下面来看看`fire`的基础用法，假设`example.py`文件内容如下：\n",
    "```python\n",
    "\n",
    "import fire\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "  \n",
    "def mul(**kwargs):\n",
    "    a = kwargs['a']\n",
    "    b = kwargs['b']\n",
    "    return a * b\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fire.Fire()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:07:46.984805Z",
     "start_time": "2020-12-14T09:07:46.649785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "!python example.py add 1 2 # 执行add(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:07:57.101089Z",
     "start_time": "2020-12-14T09:07:56.802035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "!python example.py mul --a=1 --b=2 # 执行mul(a=1, b=2), kwargs={'a':1, 'b':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:08:08.528447Z",
     "start_time": "2020-12-14T09:08:08.287488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "!python example.py add --x=1 --y=2 # 执行add(x=1, y=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "可见，只要在程序中运行`fire.Fire()`，即可使用命令行参数`python file <function> [args,] {--kwargs,}`。fire还支持更多的高级功能，具体请参考官方指南[^4] 。\n",
    "\n",
    "[^3]: https://github.com/google/python-fire\n",
    "[^4]: https://github.com/google/python-fire/blob/master/doc/guide.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在主程序`main.py`中，主要包含四个函数，其中三个需要命令行执行，`main.py`的代码组织结构如下：\n",
    "\n",
    "```python\n",
    "def train(**kwargs):\n",
    "    \"\"\"\n",
    "    训练\n",
    "    \"\"\"\n",
    "    pass\n",
    "\t \n",
    "def val(model, dataloader):\n",
    "    \"\"\"\n",
    "    计算模型在验证集上的准确率等信息，用以辅助训练\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def test(**kwargs):\n",
    "    \"\"\"\n",
    "    测试（inference）\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def help():\n",
    "    \"\"\"\n",
    "    打印帮助的信息 \n",
    "    \"\"\"\n",
    "    print('help')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    import fire\n",
    "    fire.Fire()\n",
    "```\n",
    "\n",
    "根据fire的使用方法，可通过`python main.py <function> --args=xx`的方式来执行训练或者测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的主要步骤如下：\n",
    "\n",
    "- 定义网络\n",
    "- 定义数据\n",
    "- 定义损失函数和优化器\n",
    "- 计算重要指标\n",
    "- 开始训练\n",
    "  - 训练网络\n",
    "  - 可视化各种指标\n",
    "  - 计算在验证集上的指标\n",
    "\n",
    "训练函数的代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:19:43.155189Z",
     "start_time": "2020-12-14T09:19:43.143221Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "    \n",
    "    # 根据命令行参数更新配置\n",
    "    opt.parse(kwargs)\n",
    "    vis = Visualizer(opt.env)\n",
    "    \n",
    "    # step1: 模型\n",
    "    model = getattr(models, opt.model)()\n",
    "    if opt.load_model_path:\n",
    "        model.load(opt.load_model_path)\n",
    "    if opt.use_gpu: model.cuda()\n",
    "\n",
    "    # step2: 数据\n",
    "    train_data = DogCat(opt.train_data_root,train=True)\n",
    "    val_data = DogCat(opt.train_data_root,train=False)\n",
    "    train_dataloader = DataLoader(train_data,opt.batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=opt.num_workers)\n",
    "    val_dataloader = DataLoader(val_data,opt.batch_size,\n",
    "                        shuffle=False,\n",
    "                        num_workers=opt.num_workers)\n",
    "    \n",
    "    # step3: 目标函数和优化器\n",
    "    criterion = t.nn.CrossEntropyLoss()\n",
    "    lr = opt.lr\n",
    "    optimizer = t.optim.Adam(model.parameters(),\n",
    "                            lr = lr,\n",
    "                            weight_decay = opt.weight_decay)\n",
    "        \n",
    "    # step4: 统计指标：平滑处理之后的损失，还有混淆矩阵\n",
    "    loss_meter = meter.AverageValueMeter()\n",
    "    confusion_matrix = meter.ConfusionMeter(2)\n",
    "    previous_loss = 1e100\n",
    "\n",
    "    # 训练\n",
    "    for epoch in range(opt.max_epoch):\n",
    "        \n",
    "        loss_meter.reset()\n",
    "        confusion_matrix.reset()\n",
    "\n",
    "        for ii,(data,label) in enumerate(train_dataloader):\n",
    "\n",
    "            # 训练模型参数 \n",
    "            input = Variable(data)\n",
    "            target = Variable(label)\n",
    "            if opt.use_gpu:\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "            optimizer.zero_grad() #梯度置零\n",
    "            score = model(input) #模型预测\n",
    "            loss = criterion(score,target) #损失值\n",
    "            loss.backward() #反向传播\n",
    "            optimizer.step() #更新参数值\n",
    "            \n",
    "            # 更新统计指标以及可视化\n",
    "            loss_meter.add(loss.data[0])\n",
    "            confusion_matrix.add(score.data, target.data)\n",
    "\n",
    "            if ii%opt.print_freq==opt.print_freq-1:\n",
    "                vis.plot('loss', loss_meter.value()[0])\n",
    "                \n",
    "                # 如果需要的话，进入debug模式\n",
    "                if os.path.exists(opt.debug_file):\n",
    "                    import ipdb;\n",
    "                    ipdb.set_trace()\n",
    "\n",
    "        model.save()\n",
    "\n",
    "        # 计算验证集上的指标及可视化\n",
    "        val_cm,val_accuracy = val(model,val_dataloader)\n",
    "        vis.plot('val_accuracy',val_accuracy)\n",
    "        vis.log(\"epoch:{epoch},lr:{lr},loss:{loss},train_cm:{train_cm},val_cm:{val_cm}\"\n",
    "        .format(\n",
    "                    epoch = epoch,\n",
    "                    loss = loss_meter.value()[0],\n",
    "                    val_cm = str(val_cm.value()),\n",
    "                    train_cm=str(confusion_matrix.value()),\n",
    "                    lr=lr))\n",
    "        \n",
    "        # 如果损失不再下降，则降低学习率\n",
    "        if loss_meter.value()[0] > previous_loss:          \n",
    "            lr = lr * opt.lr_decay\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "                \n",
    "        previous_loss = loss_meter.value()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里用到了PyTorchNet[^5]里面的一个工具: meter。meter提供了一些轻量级的工具，用于帮助用户快速统计训练过程中的一些指标。`AverageValueMeter`能够计算所有数的平均值和标准差，这里用来统计一个epoch中损失的平均值。`confusionmeter`用来统计分类问题中的分类情况，是一个比准确率更详细的统计指标。例如对于表格6-1，共有50张狗的图片，其中有35张被正确分类成了狗，还有15张被误判成猫；共有100张猫的图片，其中有91张被正确判为了猫，剩下9张被误判成狗。相比于准确率等统计信息，混淆矩阵更能体现分类的结果，尤其是在样本比例不均衡的情况下。\n",
    "表6-1 混淆矩阵\n",
    "\n",
    "| 样本   | 判为狗  | 判为猫  |\n",
    "| ---- | ---- | ---- |\n",
    "| 实际是狗 | 35   | 15   |\n",
    "| 实际是猫 | 9    | 91   |\n",
    "\n",
    "PyTorchNet从TorchNet[^6]迁移而来，提供了很多有用的工具，但其目前开发和文档都还不是很完善，本书不做过多的讲解。\n",
    "\n",
    "[^5]: https://github.com/pytorch/tnt\n",
    "[^6]: https://github.com/torchnet/torchnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证相对来说比较简单，但要注意需将模型置于验证模式(`model.eval()`)，验证完成后还需要将其置回为训练模式(`model.train()`)，这两句代码会影响`BatchNorm`和`Dropout`等层的运行模式。验证模型准确率的代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:22:02.519667Z",
     "start_time": "2020-12-14T09:22:02.513682Z"
    }
   },
   "outputs": [],
   "source": [
    "def val(model,dataloader):\n",
    "    \"\"\"\n",
    "    计算模型在验证集上的准确率等信息\n",
    "    \"\"\"\n",
    "\n",
    "    # 把模型设为验证模式\n",
    "    model.eval()\n",
    "    \n",
    "    confusion_matrix = meter.ConfusionMeter(2)\n",
    "    for ii, data in enumerate(dataloader):\n",
    "        input, label = data\n",
    "        val_input = Variable(input, volatile=True)\n",
    "        val_label = Variable(label.long(), volatile=True)\n",
    "        if opt.use_gpu:\n",
    "            val_input = val_input.cuda()\n",
    "            val_label = val_label.cuda()\n",
    "        score = model(val_input)\n",
    "        confusion_matrix.add(score.data.squeeze(), label.long())\n",
    "\n",
    "    # 把模型恢复为训练模式\n",
    "    model.train()\n",
    "    \n",
    "    cm_value = confusion_matrix.value()\n",
    "    accuracy = 100. * (cm_value[0][0] + cm_value[1][1]) /\\\n",
    "\t\t\t     (cm_value.sum())\n",
    "    return confusion_matrix, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试时，需要计算每个样本属于狗的概率，并将结果保存成csv文件。测试的代码与验证比较相似，但需要自己加载模型和数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:22:42.808898Z",
     "start_time": "2020-12-14T09:22:42.802884Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(**kwargs):\n",
    "    opt.parse(kwargs)\n",
    "    \n",
    "    # 模型\n",
    "    model = getattr(models, opt.model)().eval()\n",
    "    if opt.load_model_path:\n",
    "        model.load(opt.load_model_path)\n",
    "    if opt.use_gpu: model.cuda()\n",
    "\n",
    "    # 数据\n",
    "    train_data = DogCat(opt.test_data_root,test=True)\n",
    "    test_dataloader = DataLoader(train_data,\\\n",
    "\t\t\t\t\t\t\t    batch_size=opt.batch_size,\\\n",
    "\t\t\t\t\t\t\t    shuffle=False,\\\n",
    "\t\t\t\t\t\t\t    num_workers=opt.num_workers)\n",
    "    \n",
    "    results = []\n",
    "    for ii,(data,path) in enumerate(test_dataloader):\n",
    "        input = t.autograd.Variable(data,volatile = True)\n",
    "        if opt.use_gpu: input = input.cuda()\n",
    "        score = model(input)\n",
    "        probability = t.nn.functional.softmax\\\n",
    "\t        (score)[:,1].data.tolist()      \n",
    "        batch_results = [(path_,probability_) \\\n",
    "\t        for path_,probability_ in zip(path,probability) ]\n",
    "        results += batch_results\n",
    "    write_csv(results,opt.result_file)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 帮助函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方便他人使用, 程序中还应当提供一个帮助函数，用于说明函数是如何使用。程序的命令行接口中有众多参数，如果手动用字符串表示不仅复杂，而且后期修改config文件时，还需要修改对应的帮助信息，十分不便。这里使用了Python标准库中的inspect方法，可以自动获取config的源代码。help的代码如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-14T09:23:43.222257Z",
     "start_time": "2020-12-14T09:23:43.218269Z"
    }
   },
   "outputs": [],
   "source": [
    "def help():\n",
    "    \"\"\"\n",
    "    打印帮助的信息： python file.py help\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\"\"\n",
    "    usage : python {0} <function> [--args=value,]\n",
    "    <function> := train | test | help\n",
    "    example: \n",
    "            python {0} train --env='env0701' --lr=0.01\n",
    "            python {0} test --dataset='path/to/dataset/root/'\n",
    "            python {0} help\n",
    "    avaiable args:\"\"\".format(__file__))\n",
    "\n",
    "    from inspect import getsource\n",
    "    source = (getsource(opt.__class__))\n",
    "    print(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当用户执行`python main.py help`的时候，会打印如下帮助信息：\n",
    "\n",
    "```bash\n",
    "    usage : python main.py <function> [--args=value,]\n",
    "    <function> := train | test | help\n",
    "    example: \n",
    "            python main.py train --env='env0701' --lr=0.01\n",
    "            python main.py test --dataset='path/to/dataset/'\n",
    "            python main.py help\n",
    "    avaiable args:\n",
    "class DefaultConfig(object):\n",
    "    env = 'default' # visdom 环境\n",
    "    model = 'AlexNet' # 使用的模型\n",
    "    \n",
    "    train_data_root = './data/train/' # 训练集存放路径\n",
    "    test_data_root = './data/test1' # 测试集存放路径\n",
    "    load_model_path = 'checkpoints/model.pth' # 加载预训练的模型\n",
    "\n",
    "    batch_size = 128 # batch size\n",
    "    use_gpu = True # user GPU or not\n",
    "    num_workers = 4 # how many workers for loading data\n",
    "    print_freq = 20 # print info every N batch\n",
    "\n",
    "    debug_file = '/tmp/debug' \n",
    "    result_file = 'result.csv' # 结果文件\n",
    "      \n",
    "    max_epoch = 10\n",
    "    lr = 0.1 # initial learning rate\n",
    "    lr_decay = 0.95 # when val_loss increase, lr = lr*lr_decay\n",
    "    weight_decay = 1e-4 # 损失函数\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正如`help`函数的打印信息所述，可以通过命令行参数指定变量名.下面是三个使用例子，fire会将包含`-`的命令行参数自动转层下划线`_`，也会将非数值的值转成字符串。所以`--train-data-root=data/train`和`--train_data_root='data/train'`是等价的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# 训练模型\n",
    "python main.py train \n",
    "        --train-data-root=data/train/ \n",
    "        --lr=0.005 \n",
    "        --batch-size=32 \n",
    "        --model='ResNet34'  \n",
    "        --max-epoch = 20\n",
    "\n",
    "# 测试模型\n",
    "python main.py test\n",
    "       --test-data-root=data/test1 \n",
    "       --load-model-path='checkpoints/resnet34_00:23:05.pth' \n",
    "       --batch-size=128 \n",
    "       --model='ResNet34' \n",
    "       --num-workers=12\n",
    "\n",
    "# 打印帮助信息\n",
    "python main.py help\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 争议"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上的程序设计规范带有作者强烈的个人喜好，并不想作为一个标准，而是作为一个提议和一种参考。上述设计在很多地方还有待商榷，例如对于训练过程是否应该封装成一个`trainer`对象，或者直接封装到`BaiscModule`的`train`方法之中。对命令行参数的处理也有不少值得讨论之处。因此不要将本文中的观点作为一个必须遵守的规范，而应该看作一个参考。\n",
    "\n",
    "本章中的设计可能会引起不少争议，其中比较值得商榷的部分主要有以下两个方面：\n",
    "\n",
    "- 命令行参数的设置。目前大多数程序都是使用Python标准库中的`argparse`来处理命令行参数，也有些使用比较轻量级的`click`。这种处理相对来说对命令行的支持更完备，但根据作者的经验来看，这种做法不够直观，并且代码量相对来说也较多。比如`argparse`，每次增加一个命令行参数，都必须写如下代码：\n",
    "\n",
    "```python\n",
    "parser.add_argument('-save-interval', type=int, default=500, help='how many steps to wait before saving [default:500]')\n",
    "```\n",
    "\n",
    "在读者眼中，这种实现方式远不如一个专门的`config.py`来的直观和易用。尤其是对于使用Jupyter notebook或IPython等交互式调试的用户来说，`argparse`较难使用。\n",
    "\n",
    "- 模型训练。有不少人喜欢将模型的训练过程集成于模型的定义之中，代码结构如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "  class MyModel(nn.Module):\n",
    "  \t\n",
    "      def __init__(self,opt):\n",
    "          self.dataloader = Dataloader(opt)\n",
    "          self.optimizer  = optim.Adam(self.parameters(),lr=0.001)\n",
    "          self.lr = opt.lr\n",
    "          self.model = make_model()\n",
    "      \n",
    "      def forward(self,input):\n",
    "          pass\n",
    "      \n",
    "      def train_(self):\n",
    "          # 训练模型\n",
    "          for epoch in range(opt.max_epoch)\n",
    "          \tfor ii,data in enumerate(self.dataloader):\n",
    "              \ttrain_epoch()\n",
    "              \n",
    "          \tmodel.save()\n",
    "  \t\n",
    "      def train_epoch(self):\n",
    "          pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "抑或是专门设计一个`Trainer`对象，形如：\n",
    "\n",
    "```python\n",
    "    \"\"\"\n",
    "  code simplified from:\n",
    "  https://github.com/pytorch/pytorch/blob/master/torch/utils/trainer/trainer.py\n",
    "  \"\"\"\n",
    "  import heapq\n",
    "  from torch.autograd import Variable\n",
    "\n",
    "  class Trainer(object):\n",
    "\n",
    "      def __init__(self, model=None, criterion=None, optimizer=None, dataset=None):\n",
    "          self.model = model\n",
    "          self.criterion = criterion\n",
    "          self.optimizer = optimizer\n",
    "          self.dataset = dataset\n",
    "          self.iterations = 0\n",
    "\n",
    "      def run(self, epochs=1):\n",
    "          for i in range(1, epochs + 1):\n",
    "              self.train()\n",
    "\n",
    "      def train(self):\n",
    "          for i, data in enumerate(self.dataset, self.iterations + 1):\n",
    "              batch_input, batch_target = data\n",
    "              self.call_plugins('batch', i, batch_input, batch_target)\n",
    "              input_var = Variable(batch_input)\n",
    "              target_var = Variable(batch_target)\n",
    "    \n",
    "              plugin_data = [None, None]\n",
    "    \n",
    "              def closure():\n",
    "                  batch_output = self.model(input_var)\n",
    "                  loss = self.criterion(batch_output, target_var)\n",
    "                  loss.backward()\n",
    "                  if plugin_data[0] is None:\n",
    "                      plugin_data[0] = batch_output.data\n",
    "                      plugin_data[1] = loss.data\n",
    "                  return loss\n",
    "    \n",
    "              self.optimizer.zero_grad()\n",
    "              self.optimizer.step(closure)\n",
    "    \n",
    "          self.iterations += i\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一些人喜欢模仿keras和scikit-learn的设计，设计一个`fit`接口。对读者来说，这些处理方式很难说哪个更好或更差，找到最适合自己的方法才是最好的。\n",
    "\n",
    "`BasicModule` 的封装，可多可少。训练过程中的很多操作都可以移到`BasicModule`之中，比如`get_optimizer`方法用来获取优化器，比如`train_step`用来执行单歩训练。对于不同的模型，如果对应的优化器定义不一样，或者是训练方法不一样，可以复写这些函数自定义相应的方法，取决于自己的喜好和项目的实际需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型跑批"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练脚本:\n",
    "```\n",
    "python main.py train  --use_gpu=False --num_workers=0 --env=classifier\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试脚本:\n",
    "```\n",
    "python main.py  test --use-gpu=False --batch-size=128\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch] *",
   "language": "python",
   "name": "conda-env-.conda-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
